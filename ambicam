#!/usr/bin/python
import argparse
import cv2
import json
import numpy as np
import picamera
import picamera.array
import pickle
import signal
import socket
import sys
import time

# TODO make configurable
HOST = '192.168.1.104'
PORT = 19444
PRIORITY = 90
FRAMERATE = 45
OFFSET = 10

def compute_map(M_inv, x, y, width, height):
    coords = []
    for j in range(int(y), int(y+height)):
        for i in range(int(x), int(x+width)):
            coords.append([i, j, 1])
    return np.dot(M_inv, np.array(coords).T).astype('float32')

class HyperionOutput(picamera.array.PiRGBAnalysis):
    def __init__(self, camera, sock, options, M, width, height, offset=10):
        super(HyperionOutput, self).__init__(camera)
        self.sock = sock
        self.options = options
        self.width = int(width)
        self.height = int(height)
        self.offset = offset
        # Calculate source image maps
        # TODO(SN): calculate corners only on top/bottom?
        M_inv = np.linalg.inv(M)
        self.top_map = compute_map(M_inv, 0, 0, width, offset)
        self.left_map = compute_map(M_inv, 0, 0, offset, height)
        self.right_map = compute_map(M_inv, width-offset, 0, offset, height)
        self.bottom_map = compute_map(M_inv, 0, height-offset, width, offset)
        self.start= time.perf_counter()
        if self.options.preview:
            cv2.namedWindow('input', cv2.WINDOW_NORMAL)
            cv2.namedWindow('warped', cv2.WINDOW_GUI_EXPANDED)

    def analyze(self, img):
        capture = time.perf_counter()
        # Warp image map-by-map
        top = cv2.blur(cv2.remap(img, self.top_map[0], self.top_map[1],
                                     cv2.INTER_LINEAR).reshape(self.offset,self.width,3),
                       (5,5))
        left = cv2.blur(cv2.remap(img, self.left_map[0], self.left_map[1],
                                      cv2.INTER_LINEAR).reshape(self.height,self.offset,3),
                        (5,5))
        right = cv2.blur(cv2.remap(img, self.right_map[0], self.right_map[1],
                                       cv2.INTER_LINEAR).reshape(self.height,self.offset,3),
                         (5,5))
        bottom = cv2.blur(cv2.remap(img, self.bottom_map[0], self.bottom_map[1],
                                        cv2.INTER_LINEAR).reshape(self.offset,self.width,3),
                          (5,5))
        if self.options.profile:
            warp = time.perf_counter()
            print('warp:', warp - capture)
        if not self.options.nosend:
            # Extract and send colors
            # TODO twice as expensive as remap + blur!!
            # TODO use led geometry from hyperion
            colors  = []
            for i in range(19): # bottom center -> bottom left
                col = (self.width/2)-i*(self.width/2-self.offset)/19
                colors.extend(bottom[self.offset/2, col].tolist())
            for i in range(20): # bottom left -> top left
                row = (self.height-self.offset)-i*(self.height-2*self.offset)/20
                colors.extend(left[row, self.offset/2].tolist())
            for i in range(36): # top left -> top right
                col = self.offset+i*(self.width-2*self.offset)/36
                colors.extend(top[self.offset/2, col].tolist())
            for i in range(20): # top left -> bottom left
                row = self.offset+i*(self.height-2*self.offset)/20
                colors.extend(right[row, self.offset/2].tolist())
            for i in range(17): # bottom right -> bottom center
                col = (self.width-self.offset)-i*(self.width/2-self.offset)/17
                colors.extend(bottom[self.offset/2, col].tolist())
            if self.options.profile:
                extract = time.perf_counter()
                print('extract:', extract - warp)
            hyperion_color(self.sock, PRIORITY, colors)
            if self.options.profile:
                send = time.perf_counter()
                print('send:', send - warp)
        img_rgb = None
        if self.options.output:
            img_rgb = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            cv2.imwrite(self.options.output, img_rgb)
        if self.options.preview:
            if img_rgb is None:
                img_rgb = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            cv2.imshow('input', img_rgb)
            # Stitch and preview
            warped = np.zeros((self.height, self.width, 3), dtype='uint8')
            warped[:self.offset,:] += top
            warped[self.offset:-self.offset,:self.offset] += left[self.offset:-self.offset,:]
            warped[self.offset:-self.offset,self.width-self.offset:] += right[self.offset:-self.offset,:]
            warped[self.height-self.offset:,:] += bottom
            warped_rgb = cv2.cvtColor(warped, cv2.COLOR_RGB2BGR)
            cv2.imshow('warped', warped_rgb)
            cv2.waitKey(100)
        if self.options.profile:
            print('FPS: ', 1 / (time.perf_counter() - self.start))
        self.start = time.perf_counter()

def hyperion_color(sock, priority, colors):
    cmd = json.dumps({
        'command': 'color',
        'priority': priority,
        'color': colors
    }) + '\n'
    sock.sendall(cmd.encode('utf-8'))

def hyperion_clearall(sock):
    cmd = json.dumps({'command': 'clearall'}) + '\n'
    sock.sendall(cmd.encode('utf-8'))

def print_camera_info(camera):
    print('--- Camera info ---')
    print('analog_gain: ', float(camera.analog_gain))
    print('awb_mode: ', camera.awb_mode)
    print('awb_gains: %f %f' % camera.awb_gains)
    print('brightness: ', camera.brightness)
    print('contrast: ', camera.contrast)
    print('digital_gain: ', float(camera.digital_gain))
    print('drc_strength: ', camera.drc_strength)
    print('exposure_compensation: ', camera.exposure_compensation)
    print('exposure_mode: ', camera.exposure_mode)
    print('exposure_speed: ', camera.exposure_speed)
    print('iso: ', camera.iso)
    print('meter_mode', camera.meter_mode)
    print('resolution', camera.resolution)
    print('saturation: ', camera.saturation)
    print('sensor_mode: ', camera.sensor_mode)
    print('sharpness: ', camera.sharpness)
    print('shutter_speed: ', camera.shutter_speed)
    print('video_denoise: ', camera.video_denoise)
    print('video_stabilization: ', camera.video_stabilization)

def load_calibration(path):
    with open(path, 'rb') as file:
        return pickle.load(file)

def print_calibration(c):
    print('source resolution: ', c['source'])
    print('target resolution: ', c['target'])
    print('transformation:\n', c['matrix'])

def main():
    parser = argparse.ArgumentParser(description='AmbiCam runtime')
    parser.add_argument('-c', '--calibration', default='ambicam.calib',
                        help='path to calibration')
    parser.add_argument('-n', '--nosend', dest='nosend', action='store_true',
                        help='disable color extraction and sending')
    parser.add_argument('-p', '--preview', dest='preview', action='store_true',
                        help='show captured and warped images (slow!)')
    parser.add_argument('-o', '--output', dest='output',
                        help='save captured image to file')
    parser.add_argument('--profile', dest='profile', action='store_true',
                        help='print profiling info like fps of processing loop')
    parser.add_argument('--camera-info', dest='camera_info', action='store_true',
                        help='print camera info')
    parser.add_argument('--awb-mode', dest='awb_mode', default='auto',
                        help='automatic white balance mode')
    parser.add_argument('--awb-gain-red', dest='awb_gain_red', type=float, default=1.4,
                        help='automatic white balance gain for red (only in mode: auto)')
    parser.add_argument('--awb-gain-blue', dest='awb_gain_blue', type=float, default=1.3,
                        help='automatic white balance gain for blue (only in mode: auto)')
    parser.add_argument('--iso', dest='iso', type=int, default=0,
                        help='light sensitivity')
    parser.add_argument('--exposure-mode', dest='exposure_mode', default='backlight',
                        help='automatic exposure adjustment mode')
    parser.add_argument('--shutter-speed', dest='shutter_speed', type=int, default=0,
                        help='target shutter speed in microseconds')
    parser.add_argument('--meter-mode', dest='meter_mode', default='backlit',
                        help='area used to calculate exposure')
    parser.add_argument('--brightness', type=int, default=50,
                        help='image brightness')
    parser.add_argument('--saturation', type=int, default=-30,
                        help='image saturation')
    options = parser.parse_args()

    calibration = load_calibration(options.calibration)
    print('loaded calibration:')
    print_calibration(calibration)
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.connect((HOST, PORT))
    print('connected to %s:%s' % (HOST, PORT))

    def sigint(signal, frame):
        if not options.nosend:
            hyperion_clearall(sock)
        sock.close()
        sys.exit(0)
    signal.signal(signal.SIGINT, sigint)

    with picamera.PiCamera(resolution=calibration['source'], framerate=FRAMERATE) as camera:
        camera.awb_mode = options.awb_mode
        camera.awb_gains = (options.awb_gain_red, options.awb_gain_blue)
        camera.brightness = options.brightness
        if options.exposure_mode != 'off':
            camera.exposure_mode = options.exposure_mode
        camera.iso = options.iso
        camera.meter_mode = options.meter_mode
        camera.saturation = options.saturation
        camera.shutter_speed = options.shutter_speed
        camera.video_denoise = False
        with HyperionOutput(camera,
                            sock,
                            options,
                            calibration['matrix'],
                            calibration['target'][0],
                            calibration['target'][1],
                            offset=OFFSET) as output:
            camera.start_recording(output, 'rgb')
            try:
                while True:
                    camera.wait_recording(1)
                    if options.camera_info:
                        print_camera_info(camera)
                    # Delay exposure mode setting for 'off' to have gains >= 0
                    if options.exposure_mode == 'off' and camera.exposure_mode != 'off':
                        camera.exposure_mode = 'off'
            finally:
                camera.stop_recording()

if __name__ == '__main__':
    main()
