#!/usr/bin/python
import argparse
import cv2
import json
import picamera
import picamera.array
import numpy as np
import pickle
import signal
import socket
import sys
import time

# TODO make configurable
HOST = '192.168.1.104'
PORT = 19444
PRIORITY = 90
OFFSET = 20

def compute_warp_map(M_inv, x, y, width, height):
    coords = []
    for j in np.arange(y, y+height):
        for i in np.arange(x, x+width):
            coords.append([i, j, 1])
    return np.dot(M_inv, np.array(coords).T).astype('float32')

def led_map(width, height, offset):
    # TODO use led geometry from hyperion
    coords = []
    for i in range(19): # bottom center -> bottom left
        col = width/2-i*(width/2-offset)/19
        coords.append((height-offset/2, col))
    for i in range(20): # bottom left -> top left
        row = (height-offset)-i*(height-offset*2)/20
        coords.append((row, offset/2))
    for i in range(36): # top left -> top right
        col = offset+i*(width-offset*2)/36
        coords.append((width-offset/2, col))
    for i in range(20): # top right -> bottom right
        row = offset+i*(height-offset*2)/20
        coords.append((row, width-offset/2))
    for i in range(17): # bottom right -> bottom center
        col = (width-offset)-i*(width/2-offset)/17
        coords.append((height-offset/2, col))
    return np.array(coords, dtype=np.float32)

class HyperionOutput(picamera.array.PiRGBAnalysis):
    def __init__(self, camera, sock, options, M, width, height, offset=10):
        super(HyperionOutput, self).__init__(camera)
        self.sock = sock
        self.options = options
        self.width = width
        self.height = height
        self.offset = offset
        # Calculate source image maps (corner areas are doubled for convenience)
        self.M_inv = np.linalg.inv(M)
        # TODO broken!?
        # self.top_map = compute_warp_map(M_inv, 0, 0, width, offset)
        # self.left_map = compute_warp_map(M_inv, 0, 0, offset, height)
        # self.right_map = compute_warp_map(M_inv, width-offset, 0, offset, height)
        # self.bottom_map = compute_warp_map(M_inv, 0, height-offset, width, offset)
        self.led_map = led_map(width, height, offset)
        self.start= time.perf_counter()
        if self.options.preview:
            cv2.namedWindow('input', cv2.WINDOW_NORMAL)
            cv2.namedWindow('warped', cv2.WINDOW_GUI_EXPANDED)

    def analyze(self, img):
        capture = time.perf_counter()
        # Warp image map-by-map
        # TODO commented out method broken!?
        warped = cv2.warpPerspective(img, self.M_inv, (self.width, self.height), flags=cv2.WARP_INVERSE_MAP)
        blurred = cv2.blur(warped, (31,31))
        # top = cv2.blur(warped[:self.offset,:], (31,31))
        # top = cv2.blur(cv2.remap(img, self.top_map[0], self.top_map[1],
        #                              cv2.INTER_LINEAR).reshape(self.offset,self.width,3),
        #                (31,31))
        # left = cv2.blur(warped[:,:self.offset], (31,31))
        # left = cv2.blur(cv2.remap(img, self.left_map[0], self.left_map[1],
        #                               cv2.INTER_LINEAR).reshape(self.height,self.offset,3),
        #                 (31,31))
        # right = cv2.blur(warped[:,-self.offset:], (31,31))
        # right = cv2.blur(cv2.remap(img, self.right_map[0], self.right_map[1],
        #                                cv2.INTER_LINEAR).reshape(self.height,self.offset,3),
        #                  (31,31))
        # bottom = cv2.blur(warped[-self.offset:,:], (31,31))
        # bottom = cv2.blur(cv2.remap(img, self.bottom_map[0], self.bottom_map[1],
        #                                 cv2.INTER_LINEAR).reshape(self.offset,self.width,3),
        #                   (31,31))
        if self.options.profile:
            warp = time.perf_counter()
            print('warp:', warp - capture)
        if not self.options.nosend:
            # Extract and send colors
            colors = cv2.remap(blurred, self.led_map[:,0], self.led_map[:,1], cv2.INTER_LINEAR)
            if self.options.profile:
                extract = time.perf_counter()
                print('extract:', extract - warp)
            hyperion_color(self.sock, PRIORITY, colors.ravel().tolist())
            if self.options.profile:
                send = time.perf_counter()
                print('send:', send - extract)
        img_bgr = None
        if self.options.output:
            img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            cv2.imwrite(self.options.output, img_bgr)
        if self.options.preview:
            if img_bgr is None:
                img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            cv2.imshow('input', img_bgr)
            # Stitch and preview
            # warped = np.zeros((self.height, self.width, 3), dtype='uint8')
            # warped[:self.offset,:] += top
            # warped[self.offset:-self.offset,:self.offset] += left[self.offset:-self.offset,:]
            # warped[self.offset:-self.offset,self.width-self.offset:] += right[self.offset:-self.offset,:]
            # warped[self.height-self.offset:,:] += bottom
            warped_bgr = cv2.cvtColor(warped, cv2.COLOR_RGB2BGR)
            cv2.imshow('warped', warped_bgr)
            cv2.waitKey(100)
        if self.options.profile:
            print('FPS: ', 1 / (time.perf_counter() - self.start))
        self.start = time.perf_counter()

def hyperion_color(sock, priority, colors):
    cmd = json.dumps({
        'command': 'color',
        'priority': priority,
        'color': colors
    }) + '\n'
    sock.sendall(cmd.encode('utf-8'))

def hyperion_clearall(sock):
    cmd = json.dumps({'command': 'clearall'}) + '\n'
    sock.sendall(cmd.encode('utf-8'))

def print_camera_info(camera):
    print('--- Camera info ---')
    print('analog_gain: ', float(camera.analog_gain))
    print('awb_mode: ', camera.awb_mode)
    print('awb_gains: %f %f' % camera.awb_gains)
    print('brightness: ', camera.brightness)
    print('contrast: ', camera.contrast)
    print('digital_gain: ', float(camera.digital_gain))
    print('drc_strength: ', camera.drc_strength)
    print('exposure_compensation: ', camera.exposure_compensation)
    print('exposure_mode: ', camera.exposure_mode)
    print('exposure_speed: ', camera.exposure_speed)
    print('iso: ', camera.iso)
    print('meter_mode', camera.meter_mode)
    print('resolution', camera.resolution)
    print('saturation: ', camera.saturation)
    print('sharpness: ', camera.sharpness)
    print('shutter_speed: ', camera.shutter_speed)
    print('video_denoise: ', camera.video_denoise)
    print('video_stabilization: ', camera.video_stabilization)

def load_calibration(path):
    with open(path, 'rb') as file:
        return pickle.load(file)

def print_calibration(c):
    print('source resolution: ', c['source'])
    print('target resolution: ', c['target'])
    print('transformation:\n', c['matrix'])

def main():
    parser = argparse.ArgumentParser(description='AmbiCam runtime', add_help=False)
    parser.add_argument('--help', action='help', help='show this help message')
    parser.add_argument('-n', '--nosend', dest='nosend', action='store_true',
                        help='disable color extraction and sending')
    parser.add_argument('-p', '--preview', dest='preview', action='store_true',
                        help='show captured and warped images (slow!)')
    parser.add_argument('--profile', dest='profile', action='store_true',
                        help='print profiling info like fps of processing loop')
    parser.add_argument('--camera-info', dest='camera_info', action='store_true',
                        help='print camera info')
    parser.add_argument('-c', '--calibration', default='ambicam.calib',
                        help='path to calibration')
    parser.add_argument('-o', '--output', dest='output',
                        help='save captured image to file')
    parser.add_argument('-w', '--width', type=int, default=1280,
                        help='width of captured image, determines sensor mode')
    parser.add_argument('-h', '--height', type=int, default=720,
                        help='height of captured image, determines sensor mode')
    parser.add_argument('-f', '--fps', dest='framerate', type=int, default=50,
                        help='capture framerate, determines sensor mode')
    parser.add_argument('-r', '--rotation', type=int, default=0,
                        help='rotate camera image (0, 90, 180, 270)')
    parser.add_argument('--awb-mode', dest='awb_mode', default='auto',
                        help='automatic white balance mode')
    parser.add_argument('--awb-gain-red', dest='awb_gain_red', type=float, default=1.4,
                        help='automatic white balance gain for red (only in mode: auto)')
    parser.add_argument('--awb-gain-blue', dest='awb_gain_blue', type=float, default=1.3,
                        help='automatic white balance gain for blue (only in mode: auto)')
    parser.add_argument('--brightness', type=int, default=50,
                        help='image brightness')
    parser.add_argument('--contrast', dest='contrast', type=int, default=0,
                        help='image contrast')
    parser.add_argument('--exposure-mode', dest='exposure_mode', default='backlight',
                        help='automatic exposure adjustment mode')
    parser.add_argument('--iso', dest='iso', type=int, default=0,
                        help='light sensitivity')
    parser.add_argument('--meter-mode', dest='meter_mode', default='backlit',
                        help='area used to calculate exposure')
    parser.add_argument('--saturation', type=int, default=-30,
                        help='image saturation')
    parser.add_argument('--shutter-speed', dest='shutter_speed', type=int, default=0,
                        help='target shutter speed in microseconds')
    options = parser.parse_args()
    resolution = (options.width, options.height)
    calibration = load_calibration(options.calibration)
    print('loaded calibration:')
    print_calibration(calibration)
    if calibration['source'] != resolution:
        print('WARNING: calibrated resolution does not match capture resolution!')
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.connect((HOST, PORT))
    print('connected to %s:%s' % (HOST, PORT))

    def sigint(signal, frame):
        if not options.nosend:
            hyperion_clearall(sock)
        sock.close()
        sys.exit(0)
    signal.signal(signal.SIGINT, sigint)
    with picamera.PiCamera(resolution=resolution, framerate=options.framerate) as camera:
        camera.awb_mode = options.awb_mode
        camera.awb_gains = (options.awb_gain_red, options.awb_gain_blue)
        camera.brightness = options.brightness
        camera.contrast = options.contrast
        if options.exposure_mode != 'off':
            camera.exposure_mode = options.exposure_mode
        camera.iso = options.iso
        camera.meter_mode = options.meter_mode
        camera.rotation = options.rotation
        camera.saturation = options.saturation
        camera.shutter_speed = options.shutter_speed
        camera.video_denoise = False
        with HyperionOutput(camera,
                            sock,
                            options,
                            calibration['matrix'],
                            calibration['target'][0],
                            calibration['target'][1],
                            offset=OFFSET) as output:
            camera.start_recording(output, 'rgb')
            try:
                while True:
                    camera.wait_recording(1)
                    if options.camera_info:
                        print_camera_info(camera)
                    # Delay exposure mode setting for 'off' to have gains >= 0
                    if options.exposure_mode == 'off' and camera.exposure_mode != 'off':
                        camera.exposure_mode = 'off'
            finally:
                camera.stop_recording()

if __name__ == '__main__':
    main()
